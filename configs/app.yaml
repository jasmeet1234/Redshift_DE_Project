app:
  name: redshift-streaming-analytics
  environment: local

kafka:
  bootstrap_servers: "localhost:9092"
  topics:
    raw_query_metrics: "query_metrics_raw"
    processed_query_metrics: "query_metrics_processed"
    raw_query_metrics_provisioned: "query_metrics_raw_provisioned"
    raw_query_metrics_serverless: "query_metrics_raw_serverless"
    processed_query_metrics_provisioned: "query_metrics_processed_provisioned"
    processed_query_metrics_serverless: "query_metrics_processed_serverless"
  consumer_groups:
    duckdb_writer: "duckdb-writer-group"
    ui_stream: "ui-stream-group"
    clickhouse_writer: "clickhouse-writer-group"

replay:
  time_scale_factor: 50
  producer_batch_size: 500
  max_events: null
  target_duration_seconds: 3600
  prefetch_rows: 5000

dataset:
  source_url: "https://s3.amazonaws.com/redshift-downloads/redset/provisioned/sample_0.001.parquet"
  format: parquet
  event_time_column: arrival_timestamp
  batch_read_size: 10000
  enforce_event_time_order: true

datasets:
  # For testing, use the 0.001 samples.
  # To switch to full datasets, replace sample_0.001.parquet with full.parquet below.
  provisioned_url: "https://s3.amazonaws.com/redshift-downloads/redset/provisioned/sample_0.001.parquet"
  serverless_url: "https://s3.amazonaws.com/redshift-downloads/redset/serverless/sample_0.001.parquet"
  format: parquet
  event_time_column: arrival_timestamp
  batch_read_size: 10000
  enforce_event_time_order: true

processing:
  missing_values:
    numeric_fill_value: 0
    string_empty_as_null: true
    normalize_strings: true
    timestamp_invalid_action: drop

  duplicates:
    enabled: true
    key_columns:
      - query_id
      - arrival_timestamp
    ttl_seconds: 3600

  inconsistencies:
    clip_negative_durations: true
    clip_negative_metrics: true
    enforce_end_after_start: true
    allowed_deployment_types:
      - provisioned
      - serverless
      - unknown

  enrichment:
    compute_spill_pressure: true
    compute_queue_flag: true
    compute_duration_seconds: true

storage:
  duckdb:
    path: "./data/analytics.duckdb"
    tables:
      processed: query_metrics_processed
      rollups: query_metrics_rollups

clickhouse:
  host: "${CLICKHOUSE_HOST:localhost}"
  port: 8123
  database: "${CLICKHOUSE_DATABASE:redshift_analytics}"
  user: "${CLICKHOUSE_USER:default}"
  password: "${CLICKHOUSE_PASSWORD:}"
  tables:
    processed: "query_metrics_processed"
    rollups_minute: "query_metrics_rollups_minute"

ui:
  refresh_interval_seconds: 1
  stream:
    enabled: true
    topic: "query_metrics_processed_provisioned"
    max_buffer_size: 1000
